# My Development Notes

## Stream of Consciousness Notes (This will be all my own words with no AI)

Since Iris is all in on AI first development I am challenging myself to go with a more vibe code based process than I am used to. Usually I will make one update at a time while talking with the agent, allowing myself to fully understand each step. IN order to achieve as much as I can on this project, I am going to attempt to let the agent run a little bit more. I will still be checking in and consulting with it on its decisions, but I will try to not micro manage the AI. I am hoping this will allow me to have more of an impact in a short time. 

I have choose to use claude code assistant  in Jetbrains because I have some familiarity with it from Amazon (Although Amazon technically wraps our model with some internal layers). Since I have not worked on building an AI system before I relied on Claude to get some information to better understand exactly what the ask would be for this project to make sure I understood the goals and the stretch goals properly. 

Then I went into planning mode and asked Claude to give me the high level architecture. It asked me for my stack preferences and I decided that I would go with your teams recommendation of Django and Next.js because I wanted to match the environment I would be using on the job, and I could trust that it would be a good match for the project. Since I am letting Claude code for me my expertise on the language did not seem to be worth optimizing for.

It asked my for LLM for the backend and I selected Claude since I already had access. It then generated a high level architecture, complete with API routes and project structure. I reviewed the structure and it seemed very reasonable. Given the time constraints I didn't spend too long doing independent research for other options or technology stacks. My thinking with this project is that I want to learn as much as possible and have something to play with, I don't have expertize in RAG pipelines or some of these technology options and my assumption is that Claude will make a reasonable scaffolding that will allow me to build something and learn from it. Then after I have something working I can start investigating in optimizations to improve it. Since this is a small project and AI has changed the velocity at which we can code, it seems less important to me to be perfect the first time, since we can learn the lessons and quickly improve out implementation or if need be craft a new one.

I let claude finish the backend implementation and then I made sure to test a simple happy path. it seems like we are having an issue where the similarity score is coming across as low in test data that seems pretty explicit ti me. So I suspect that will be worth some energy debugging. But I am going to table it for now because lowering the threshold did work. I had a happy path testing, so now i think making a quick UI will make it easier to learn more.


I'm letting it install all the next js dependencies and run wild with an UI. I will test it and hopefully use it to better understand the whole build since there will be something to touch and the user experience will be more tangible.

The front end was created incredibly quickly and it looks very reasonable out of the box. I am going to work on getting Claude to write a lot of tests so that we can verify the behavior is the way that we suspect it should be before i go into any optimizations.

I am very impressed at how much claude can generate at a time and honestly it has been difficult to review it at the speed that it can generate. I still have time for stretch goals so I think I am going to continue to trust claude and then I will do an in depth review when it is finished. That way I can understand the whole context and I am not preventing Claude from generating

I had claude generate the last async stretch goal. it completed and wrote unit test that passed but i wanted to test it for real since we were mocking behavior. Claude has had some trouble with the environment getting celery to play nice with the other dependencies. It is working though it but this may be a weakness. I also felt like when it first ran into trouble testing it basically hand-waved and declared the incomplete tests a success. I could see this type of problem presenting challenges in other projects. It seems like claude fell back on an older python version which was causing some of the issues. To its credit it di
d say upgrading was an option but it suggested instead just trusting that the async behavior was functional. Also to be fair to it when it switched to the correct version th async behavior did work out of the box so it was correct. But I don't like that it wanted to skip the testing. 

I am a little over the 5 hour mark and I wna to honor the spirit of the exercise so I wont be implementing the front end changes that would be required to support the async changes that I started in the back end. I have an event this evening but I want to do a deep review of the full app as it is now that we have spun everything up. So my plan is to return tomorrow morning and reflect on the app with fresh eyes so I can see how valuable it is, and if there are any short comings